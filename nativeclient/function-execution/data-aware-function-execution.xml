<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE concept PUBLIC "-//OASIS//DTD DITA Concept//EN" "concept.dtd">
<concept
	id="function-execution">
	<title
		id="title_261966608351443E9C01D32A7714BAA2">Understanding Data-Aware Function
		Routing</title>
	<shortdesc>Achieving linear scalability is predicated upon being able to horizontally partition
		the application data such that concurrent operations by distributed applications can be done
		independently across partitions. </shortdesc>
	<conbody
		id="conbody_10D17FEA49F2447A86C9C5505B3328AD">
		<p
			id="p_F8008F67EB1242B0A90CC179240DB35E"> In other words, if the application requirements
			for transactions can be restricted to a single partition, and all data required for the
			transaction can be colocated to a single server member or a small subset of server
			members, then true parallelism can be achieved by vectoring the concurrent accessors to
			the ever-growing number of partitions. </p>
		<p
			id="p_920934E68EC04255A417847279C7496B">Most scalable enterprise applications grow in
			data volume, where the number of data items managed rather than the size of individual
			items grows over time. 
If the above logic
			holds (especially true for OLTP class applications), then we can derive sizable benefits
			by routing the data-dependent application code to the fabric member hosting the data.
			This routing of application code to the data of interest is called data-aware function
			routing, or behavior routing. </p>
	</conbody>
</concept>
