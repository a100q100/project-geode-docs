<?xml version="1.0"?>
<!DOCTYPE concept PUBLIC "-//OASIS//DTD DITA Concept//EN" "concept.dtd">
<concept id="concept_6C52A037E39E4FD6AE4C6A982A4A1A85">
	<title>Configuring Dispatcher Threads and Order Policy for Event Distribution</title>
	<shortdesc>By default, <keyword keyref="product_name"/> uses multiple dispatcher threads to process
		region events simultaneously in a gateway sender queue for distribution between sites, or in
		an asynchronous event queue for distributing events for write-behind caching. With serial
		queues, you can also configure the ordering policy for dispatching those events.</shortdesc>
	<prolog>
		<metadata>
			<keywords>
				<keyword> gateway sender queues</keyword>
				<keyword> gateway sender concurrency</keyword>
				<keyword> gateway sender order policy</keyword>
				<keyword> concurrent queues</keyword>
				<keyword> concurrent gateway sender WAN</keyword>
				<keyword> dispatcher threads</keyword>
				<keyword>wbcl write-behind cache listener async event queue order policy</keyword>
			</keywords>
		</metadata>
	</prolog>
	<conbody>
		<p>By default, a gateway sender queue or asynchronous event queue uses 5 dispatcher threads per
			queue. This provides support for applications that have the ability to process queued
			events concurrently for distribution to another <keyword keyref="product_name"/> site or
			listener. If your application does not require concurrent distribution, or if you do not
			have enough resources to support the requirements of multiple dispatcher threads, then
			you can configure a single dispatcher thread to process a queue. </p>
		<ul id="ul_6E0239ABB2024F68A7F11BB2DBA24DA0">
			<li id="li_ADD8D88F3A514E7386AC9A17BC0CA316">
				<xref
					href="configuring_gateway_concurrency_levels.xml#concept_6C52A037E39E4FD6AE4C6A982A4A1A85/section_20E8EFCE89EB4DC7AA822D03C8E0F470"
					type="section" format="dita" scope="local"/>
			</li>
			<li id="li_03191F9E43B04A97B34652612BF148C1">
				<xref
					href="configuring_gateway_concurrency_levels.xml#concept_6C52A037E39E4FD6AE4C6A982A4A1A85/section_C4C83B5C0FDD4913BA128365EE7E4E35"
					type="section" format="dita" scope="local"/>
			</li>
			<li id="li_8B728DB66E754B14940466669D19AF3A">
				<xref
					href="configuring_gateway_concurrency_levels.xml#concept_6C52A037E39E4FD6AE4C6A982A4A1A85/section_4835BA30CDFD4B658BD2576F6BC2E23F"
					type="section" format="dita" scope="local"/>
			</li>
			<li id="li_7177C3158A0246BD92C13FA1BD47D583">
				<xref
					href="configuring_gateway_concurrency_levels.xml#concept_6C52A037E39E4FD6AE4C6A982A4A1A85/section_752F08F9064B4F67A80DA0A994671EA0"
					type="section" format="dita" scope="local"/>
			</li>
		</ul>
		<section id="section_20E8EFCE89EB4DC7AA822D03C8E0F470">
			<title>Using Multiple Dispatcher Threads to Process a Queue</title>
			<p>When multiple dispatcher threads are configured for a parallel queue, <keyword
					keyref="product_name"/> simply uses multiple threads to process the contents of
				each individual queue. The total number of queues that are created is still
				determined by the number of <keyword keyref="product_name"/> members that host the
				region.</p>
			<p>When multiple dispatcher threads are configured for a serial queue, <keyword
					keyref="product_name"/> creates an additional copy of the queue for each thread
				on each member that hosts the queue. To obtain the maximum throughput, increase the
				number of dispatcher threads until your network is saturated. </p>
			<p>The following diagram illustrates a serial gateway sender queue that is configured with
				multiple dispatcher threads. <image id="image_093DAC58EBEE456485562C92CA79899F"
					href="../../images/MultisiteConcurrency_WAN_Gateway.png" placement="break"
					width="6.5in"/>
			</p>
		</section>
		<section id="section_C4C83B5C0FDD4913BA128365EE7E4E35">
			<title>Performance and Memory Considerations </title>
			<p>When a serial gateway sender or an asynchronous event queue uses multiple dispatcher
				threads, consider the following: </p>
				<ul id="ul_398002435B7C4C4EBC4A9C8B59F4B9CD">
					<li id="li_F62451E09C4340F1B4ADB1E4228E6B9E">Queue attributes are repeated for
						each copy of the queue that is created for a dispatcher thread. That is,
						each concurrent queue points to the same disk store, so the same disk
						directories are used. If persistence is enabled and overflow occurs, the
						threads that insert entries into the queues compete for the disk. This
						applies to application threads and dispatcher threads, so it can affect
						application performance. </li>
					<li id="li_D271ECE5BD19436AB22F556B99A03EC7">The
							<codeph>maximum-queue-memory</codeph> setting applies to each copy of
						the serial queue. If you configure 10 dispatcher threads and the maximum
						queue memory is set to 100MB, then the total maximum queue memory for the
						queue is 1000MB on each member that hosts the queue. </li>
				</ul>
		</section>
		<section id="section_4835BA30CDFD4B658BD2576F6BC2E23F">
			<title>Configuring the Ordering Policy for Serial Queues</title>
			<p>When using multiple <codeph>dispatcher-threads</codeph> (greater than 1) with a
				serial event queue, you can also configure the <codeph>order-policy</codeph> that
				those threads use to distribute events from the queue. The valid order policy values
				are: </p>
				<ul id="ul_47807C8ED95C40428931A9188AD455AD">
					<li id="li_6DADFD3B2EFF4478897C24C6D973F613"><b>key (default)</b>. All updates to the same key
						are distributed in order. <keyword keyref="product_name"/> preserves key
						ordering by placing all updates to the same key in the same dispatcher
						thread queue. You typically use key ordering when updates to entries have no
						relationship to each other, such as for an application that uses a single
						feeder to distribute stock updates to several other systems. </li>
					<li id="li_EF5FFB92865542079486EA1604AE874C"><b>thread</b>. All region updates from a given
						thread are distributed in order. <keyword keyref="product_name"/> preserves
						thread ordering by placing all region updates from the same thread into the
						same dispatcher thread queue. In general, use thread ordering when updates
						to one region entry affect updates to another region entry. </li>
					<li id="li_38BC66164C0949F48CAEB8796EDCFCB8"><b>partition</b>. All region events that share the
						same partitioning key are distributed in order. Specify partition ordering
						when applications use a <xref
							href="/releases/latest/javadoc/com/gemstone/gemfire/cache/PartitionResolver.html"
							format="html" scope="external">PartitionResolver</xref> to implement
							<xref scope="local"
							href="../partitioned_regions/using_custom_partition_resolvers.xml"
							type="concept" format="dita">custom partitioning</xref>. With partition
						ordering, all entries that share the same "partitioning key" (RoutingObject)
						are placed into the same dispatcher thread queue. </li>
				</ul>
			<p>You cannot configure the <codeph>order-policy</codeph> for a parallel event queue,
				because parallel queues cannot preserve event ordering for regions. Only the
				ordering of events for a given partition (or in a given queue of a distributed
				region) can be preserved.</p>
		</section>
		<section id="section_752F08F9064B4F67A80DA0A994671EA0">
			<title>Examplesâ€”Configuring Dispatcher Threads and Ordering Policy for a Serial Gateway
				Sender Queue</title>
			<p>To increase the number of dispatcher threads and set the ordering policy for a serial
				gateway sender, use one of the following mechanisms. </p>
				<ul
					id="ul_1D24F5A045A14338BF74A3543D61682F">
					<li id="li_E3C9DF3A23D247159131355CAD0204E2"><b>cache.xml configuration</b>
						<codeblock outputclass="language-xml">&lt;cache&gt;
  &lt;gateway-sender id="NY" parallel="false" 
   remote-distributed-system-id="1"
   enable-persistence="true"
   disk-store-name="gateway-disk-store"
   maximum-queue-memory="200"
   <b>dispatcher-threads=7 order-policy="key"</b>/&gt; 
   ... 
&lt;/cache&gt;</codeblock>
					</li>
					<li id="li_BCD0F2ACC5994D019C2E26A877AB7BF7"><b>Java API configuration</b>
						<codeblock outputclass="language-java">Cache cache = new CacheFactory().create();

GatewaySenderFactory gateway = cache.createGatewaySenderFactory();
gateway.setParallel(false);
gateway.setPersistenceEnabled(true);
gateway.setDiskStoreName("gateway-disk-store");
gateway.setMaximumQueueMemory(200);
<b>gateway.setDispatcherThreads(7);
gateway.setOrderPolicy(OrderPolicy.KEY);</b>
GatewaySender sender = gateway.create("NY", "1");
sender.start();
</codeblock></li>
					<li><b>gfsh:</b><codeblock outputclass="language-bourne">gfsh>create gateway-sender -d="NY" 
   --parallel=false 
   --remote-distributed-system-id="1"
   --enable-persistence=true
   --disk-store-name="gateway-disk-store"
   --maximum-queue-memory=200
   --dispatcher-threads=7 
   --order-policy="key"</codeblock></li>
				</ul>
			<p>The following examples show how to set dispatcher threads and ordering policy for an
				asynchronous event queue: </p>
				<ul id="ul_A2468E49D1B847DA8A86B970A6C91D30">
					<li id="li_52409A3DE9E04BB6AF4BD678108AE85B"><b>cache.xml configuration</b>
						<codeblock outputclass="language-xml">&lt;cache&gt;
   &lt;async-event-queue id="sampleQueue" persistent="true"
    disk-store-name="async-disk-store" parallel="false"
    <b>dispatcher-threads=7 order-policy="key"</b>&gt;
      &lt;async-event-listener&gt;
         &lt;class-name&gt;MyAsyncEventListener&lt;/class-name&gt;
         &lt;parameter name="url"&gt; 
           &lt;string&gt;jdbc:db2:SAMPLE&lt;/string&gt; 
         &lt;/parameter&gt; 
         &lt;parameter name="username"&gt; 
           &lt;string&gt;gfeadmin&lt;/string&gt; 
         &lt;/parameter&gt; 
         &lt;parameter name="password"&gt; 
           &lt;string&gt;admin1&lt;/string&gt; 
         &lt;/parameter&gt; 
	&lt;/async-event-listener&gt;
    &lt;/async-event-queue&gt;
...
&lt;/cache&gt;</codeblock>
					</li>
					<li id="li_6BBB4FC98CC34AE0AD442B03D66EC51E"><b>Java API configuration</b>
						<codeblock outputclass="language-java">Cache cache = new CacheFactory().create();
AsyncEventQueueFactory factory = cache.createAsyncEventQueueFactory();
factory.setPersistent(true);
factory.setDiskStoreName("async-disk-store");
factory.setParallel(false);
<b>factory.setDispatcherThreads(7);
factory.setOrderPolicy(OrderPolicy.KEY);</b>
AsyncEventListener listener = new MyAsyncEventListener();
AsyncEventQueue sampleQueue = factory.create("customerWB", listener);</codeblock>
						<p> Entry updates in the current, in-process batch are not eligible for
							conflation. </p></li>
					<li><b>gfsh:</b><codeblock outputclass="language-bourne">gfsh>create async-event-queue --id="sampleQueue" --persistent=true
--disk-store="async-disk-store" --parallel=false
--dispatcher-threads=7 order-policy="key"
--listener=myAsycEventListener 
--listener-param=url#jdbc:db2:SAMPLE 
--listener-param=username#gfeadmin 
--listener-param=password#admin1</codeblock></li>
				</ul>
		</section>
	</conbody>
</concept>
