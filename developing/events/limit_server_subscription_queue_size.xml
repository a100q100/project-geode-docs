<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE concept PUBLIC "-//OASIS//DTD DITA Concept//EN" "http://docs.oasis-open.org/dita/v1.1/OS/dtd/concept.dtd">
<concept id="limit_server_subscription_queue_size">
	<title>Limit the Server's Subscription Queue Memory Use </title>
	<conbody>
		<section id="section_1791DFB89502480EB57F81D16AC0EBAC">
			<p>These are options for limiting the amount of server memory the subscription queues
				consume. </p>
				<ul id="ul_A968819F6AA14C2B814C9515B0D7AF33">
					<li id="li_663F0115B78847349C30DF674FFAAAEA">Optional: Conflate the subscription queue
						messages. </li>
					<li id="li_A066A217A3544DBAAED60415C3BA7319">Optional: Increase the frequency of
						queue synchronization. This only applies to configurations where server
						redundancy is used for high availability. Increase the client’s pool
						configuration, <codeph>subscription-ack-interval</codeph>. The client
						periodically sends a batch acknowledgment of messages to the server, rather
						than acknowledging each message individually. A lower setting speeds message
						delivery and generally reduces traffic between the server and client. A
						higher setting helps contain server queue size. Example:
						<codeblock>&lt;!-- Set subscription ack interval to 3 seconds --&gt;
&lt;cache&gt; 
  &lt;pool ... subscription-enabled="true" 
            subscription-ack-interval="3000"&gt; 
  ... 
&lt;/pool&gt;</codeblock>You
						might want to lower the interval if you have a very busy system and want to
						reduce the space required in the servers for the subscription queues. More
						frequent acknowledgments means fewer events held in the server queues
						awaiting acknowledgment. </li>
					<li id="li_DB72604B326749C09A317D7C18E73B45">Optional: Limit Queue Size. Cap the
						server queue size using overflow or blocking. These options help avoid out
						of memory errors on the server in the case of slow clients. A slow client
						slows the rate that the server can send messages, causing messages to back
						up in the queue, possibly leading to out of memory on the server. You can
						use one or the other of these options, but not both: <ul
							id="ul_7CDCD3C1483345ED83899BEC98AE1DCF">
							<li id="li_E7C0FC9252304D1D95831F44F00FDB04">Optional: Overflow to Disk.
								Configure subscription queue overflow by setting the server’s
									<codeph>client-subscription</codeph> properties. With overflow,
								the most recently used (MRU) events are written out to disk, keeping
								the oldest events, the ones that are next in line to be sent to the
								client, available in memory. Example:
								<codeblock>&lt;!-- Set overflow after 10K messages are enqueued --&gt;
&lt;cache-server port="40404"&gt; 
  &lt;client-subscription 
    eviction-policy="entry" 
    capacity="10000" 
    disk-store-name="svrOverflow"/&gt; 
&lt;/cache-server&gt;</codeblock>
							</li>
							<li id="li_7BD3D6CD2B8E45BFBC4CBFA26390EC5B">Optional: Block While Queue
								Full. Set the server’s <codeph>maximum-message-count</codeph> to the
								maximum number of event messages allowed in any single subscription
								queue before incoming messages are blocked. You can only limit the
								message count, not the size allocated for messages. Examples:
								<p>XML:</p>
									<codeblock>&lt;!-- Set the maximum message count to 50000 entries --&gt;
  &lt;cache-server port="41414" maximum-message-count="50000" /&gt;</codeblock>
								<p>API:</p>
								<codeblock>Cache cache = ...; 
CacheServer cacheServer = cache.addCacheServer(); 
cacheServer.setPort(41414); 
cacheServer.setMaximumMessageCount(50000); 
cacheServer.start(); </codeblock>
								<p>
									<note>With this setting, one slow client can slow the server and
										all of its other clients because this blocks the threads
										that write to the queues. All operations that add messages
										to the queue block until the queue size drops to an
										acceptable level. If the regions feeding these queues are
										partitioned or have <codeph>distributed-ack</codeph> or
											<codeph>global</codeph> scope, operations on them remain
										blocked until their event messages can be added to the
										queue. If you are using this option and see stalling on your
										server region operations, your queue capacity might be too
										low for your application behavior. </note>
								</p>
							</li>
						</ul>
					</li>
				</ul>
		</section>
	</conbody>
</concept>
