<?xml version="1.0"?>
<!DOCTYPE dita PUBLIC "-//OASIS//DTD DITA Composite//EN" "ditabase.dtd">
<dita>
	<topic id="topic_7A4B6C6169BD4B1ABD356294F744D236">
		<title> Consistency Checking by Region Type</title>
		<shortdesc><keyword keyref="product_name"/> performs different consistency checks depending
			on the type of region you have configured. </shortdesc>
		<body>
			<section id="section_B090F5FB87D84104A7BE4BCEA6BAE6B7">
				<title>Partitioned Region Consistency</title>
				<p>For a partitioned region, <keyword keyref="product_name"/> maintains consistency
					by routing all updates on a given key to the <keyword keyref="product_name"/>
					member that holds the primary copy of that key. That member holds a lock on the
					key while distributing updates to other members that host a copy of the key.
					Because all updates to a partitioned region are serialized on the primary
						<keyword keyref="product_name"/> member, all members apply the updates in
					the same order and consistency is maintained at all times. See <xref
						href="../partitioned_regions/how_partitioning_works.xml" type="concept"
						format="dita" scope="local"/>. </p>
			</section>
			<section id="section_72DFB366C8F14ADBAF2A136669ECAB1E">
				<title>Replicated Region Consistency</title>
				<p>For a replicated region, any member that hosts the region can update a key and
					distribute that update to other members without locking the key. It is possible
					that two members can update the same key at the same time (a concurrent update).
					It is also possible that, due to network latency, an update in one member is
					distributed to other members at a later time, after those members have already
					applied more recent updates to the key (an out-of-order update). By default,
						<keyword keyref="product_name"/> members perform conflict checking before
					applying region updates in order to detect and consistently resolve concurrent
					and out-of-order updates. Conflict checking ensures that region data eventually
					becomes consistent on all members that host the region. The conflict checking
					behavior for replicated regions is summarized as follows: </p>
					<ul
						id="ul_A9535087E12A49949B319E538E089403">
						<li id="li_6FE8CF34CABF463E8086543BAD18A67C">If two members update the same
							key at the same time, conflict checking ensures that all members
							eventually apply the same value, which is the value of one of the two
							concurrent updates. </li>
						<li id="li_4489E072BA9649629617587EFA06456E">If a member receives an
							out-of-order update (an update that is received after one or more recent
							updates were applied), conflict checking ensures that the out-of-order
							update is discarded and not applied to the cache. </li>
					</ul>
				<p><xref
						href="#topic_C5B74CCDD909403C815639339AA03758"
						type="topic" format="dita" scope="local"/> and <xref
						href="#topic_321B05044B6641FCAEFABBF5066BD399"
						type="topic" format="dita" scope="local"/> provide more details about how
						<keyword keyref="product_name"/> performs conflict checking when applying an
					update. </p>
			</section>
			<section id="section_313045F430EE459CB411CAAE7B00F3D8">
				<title>Non-Replicated Region and Client Cache Consistency</title>
				<p>When a member receives an update for an entry in a non-replicated region and
					applies an update, it performs conflict checking in the same way as for a
					replicated region. However, if the member initiates an operation on an entry
					that is not present in the region, it first passes that operation to a member
					that hosts a replicate. The member that hosts the replica generates and provides
					the version information necessary for subsequent conflict checking. See <xref
						href="#topic_C5B74CCDD909403C815639339AA03758"
						type="topic" format="dita" scope="local"/>. </p>
				<p>Client caches also perform consistency checking in the same way when they receive
					an update for a region entry. However, all region operations that originate in
					the client cache are first passed onto an available <keyword
						keyref="product_name"/> server, which generates the version information
					necessary for subsequent conflict checking. </p>
			</section>
		</body>
	</topic>
	<topic id="topic_B64891585E7F4358A633C792F10FA23E">
		<title>Configuring Consistency Checking</title>
		<shortdesc><keyword keyref="product_name"/> enables consistency checking by default. You
			cannot disable consistency checking for persistent regions. For all other regions, you
			can explicitly enable or disable consistency checking by setting the
				<codeph>concurrency-checks-enabled</codeph> region attribute in
				<codeph>cache.xml</codeph> to "true" or "false." </shortdesc>
		<body>
			<p> All <keyword keyref="product_name"/> members that host a region must use the same
					<codeph>concurrency-checks-enabled</codeph> setting for that region. </p>
			<p>A client cache can disable consistency checking for a region even if server caches
				enable consistency checking for the same region. This configuration ensures that the
				client sees all events for the region, but it does not prevent the client cache
				region from becoming out-of-sync with the server cache. </p>
			<p>See <xref href="../../reference/topics/cache_xml.xml#region-attributes" type="topic"
				/>. </p>
			<note>
				<p>Regions that do not enable consistency checking remain subject to race conditions.
				Concurrent updates may result in one or more members having different values for the
				same key. Network latency can result in older updates being applied to a key after
				more recent updates have occurred.
				</p>
			</note>
		</body>
	</topic>
	<topic id="topic_0BDACA590B2C4974AC9C450397FE70B2">
		<title>Overhead for Consistency Checks</title>
		<shortdesc>Consistency checking requires additional overhead for storing and distributing
			version and timestamp information, as well as for maintaining destroyed entries for a
			period of time to meet consistency requirements. </shortdesc>
		<body>
			<p>To provide consistency checking, each region entry uses an additional 16 bytes. When
				an entry is deleted, a tombstone entry of approximately 13 bytes is created and
				maintained until the tombstone expires or is garbage-collected in the member. (When
				an entry is destroyed, the member temporarily retains the entry with its current
				version stamp to detect possible conflicts with operations that have occurred. The
				retained entry is referred to as a tombstone.) See <xref
					href="#topic_321B05044B6641FCAEFABBF5066BD399"
					type="topic" format="dita" scope="local"/>. </p>
			<p>If you cannot support the additional overhead in your deployment, you can disable
				consistency checks by setting <codeph>concurrency-checks-enabled</codeph> to "false"
				for each region. See <xref scope="local"
					href="region_entry_versions.xml#topic_CF2798D3E12647F182C2CEC4A46E2045"
					type="topic" format="dita"/>. </p>
		</body>
	</topic>
	<topic id="topic_C5B74CCDD909403C815639339AA03758">
		<title>How Consistency Checking Works for Replicated Regions</title>
		<shortdesc>Each region stores version and timestamp information for use in conflict
			detection. <keyword keyref="product_name"/> members use the recorded information to
			detect and resolve conflicts consistently before applying a distributed update. </shortdesc>
		<body>
			<section id="section_763B071061C94D1E82E8883325294547">
				<p>By default, each entry in a region stores the ID of the <keyword
						keyref="product_name"/> member that last updated the entry, as well as a
					version stamp for the entry that is incremented each time an update occurs. The
					version information is stored in each local entry, and the version stamp is
					distributed to other <keyword keyref="product_name"/> members when the local
					entry is updated. </p>
				<p> A <keyword keyref="product_name"/> member or client that receives an update
					message first compares the update version stamp with the version stamp recorded
					in its local cache. If the update version stamp is larger, it represents a newer
					version of the entry, so the receiving member applies the update locally and
					updates the version information. A smaller update version stamp indicates an
					out-of-order update, which is discarded. </p>
				<p>An identical version stamp indicates that multiple <keyword keyref="product_name"
					/> members updated the same entry at the same time. To resolve a concurrent
					update, a <keyword keyref="product_name"/> member always applies (or keeps) the
					region entry that has the highest membership ID; the region entry having the
					lower membership ID is discarded. </p>
				<note>
					<p>When a <keyword keyref="product_name"/> member discards an update message
					(either for an out-of-order update or when resolving a concurrent update), it
					does not pass the discarded event to an event listener for the region. You can
					track the number of discarded updates for each member using the
						<codeph>conflatedEvents</codeph> statistic. See <xref
						href="../../reference/statistics/statistics_list.xml#statistics_list"
						type="topic" format="dita" scope="local"/>. Some members may discard an
					update while other members apply the update, depending on the order in which
					each member receives the update. For this reason, the
						<codeph>conflatedEvents</codeph> statistic differs for each <keyword
						keyref="product_name"/> member. The example below describes this behavior in
					more detail.
					</p>
				</note>
				<p>The following example shows how a concurrent update is handled in a distributed
					system of three <keyword keyref="product_name"/> members. Assume that Members A,
					B, and C have membership IDs of 1, 2, and 3, respectively. Each member currently
					stores an entry, X, in their caches at version C2 (the entry was last updated by
					member C): </p>
					<ul id="ul_03309E4B02BB4C38B3DB7931117342C4">
						<li id="li_2DA56AEA4FCA42B7887C9480EA37F0A4"><b>Step 1:</b> An application
							updates entry X on <keyword keyref="product_name"/> member A at the same
							time another application updates entry X on member C. Each member
							increments the version stamp for the entry and records the version stamp
							with their member ID in their local caches. In this case the entry was
							originally at version C2, so each member updates the version to 3 (A3
							and C3, respectively) in their local caches. <p><image
									href="../../images_svg/region_entry_versions_1.svg"
									id="image_nt5_ptw_4r"/></p></li>
						<li id="li_F507BA1FCDA34409A2849386D0415ED2"><b>Step 2:</b> Member A
							distributes its update message to members B and C. <p>Member B compares
								the update version stamp (3) to its recorded version stamp (2) and
								applies the update to its local cache as version A3. In this member,
								the update is applied for the time being, and passed on to
								configured event listeners. </p><p>Member C compares the update
								version stamp (3) to its recorded version stamp (3) and identifies a
								concurrent update. To resolve the conflict, member C next compares
								the membership ID of the update to the membership ID stored in its
								local cache. Because the distributed system ID the update (A3) is
								lower than the ID stored in the cache (C3), member C discards the
								update (and increments the <codeph>conflatedEvents</codeph>
								statistic). </p><image
								href="../../images_svg/region_entry_versions_2.svg"
								id="image_ocs_35b_pr"/>
						</li>
						<li id="li_3BD5C047CD884C61AB2AD44B3A588B89"><b>Step 3:</b> Member C
							distributes the update message to members A and B. <p>Members A and B
								compare the update version stamp (3) to their recorded version
								stamps (3) and identify the concurrent update. To resolve the
								conflict, both members compare the membership ID of the update with
								the membership ID stored in their local caches. Because the
								distributed system ID of A in the cache value is less than the ID of
								C in the update, both members record the update C3 in their local
								caches, overwriting the previous value. </p><p>At this point, all
								members that host the region have achieved a consistent state for
								the concurrent updates on members A and C. </p>
							<image href="../../images_svg/region_entry_versions_3.svg"
								id="image_gsv_k5b_pr"/>
						</li>
					</ul>
			</section>
		</body>
	</topic>
	<topic id="topic_321B05044B6641FCAEFABBF5066BD399">
		<title>How Destroy and Clear Operations Are Resolved</title>
		<shortdesc>When consistency checking is enabled for a region, a <keyword
				keyref="product_name"/> member does not immediately remove an entry from the region
			when an application destroys the entry. Instead, the member retains the entry with its
			current version stamp for a period of time in order to detect possible conflicts with
			operations that have occurred. The retained entry is referred to as a <i>tombstone</i>.
				<keyword keyref="product_name"/> retains tombstones for partitioned regions and
			non-replicated regions as well as for replicated regions, in order to provide
			consistency. </shortdesc>
		<body>
			<p>A tombstone in a client cache or a non-replicated region expires after 8 minutes, at
				which point the tombstone is immediately removed from the cache. </p>
			<p>A tombstone for a replicated or partitioned region expires after 10 minutes. Expired
				tombstones are eligible for garbage collection by the <keyword keyref="product_name"
				/> member. Garbage collection is automatically triggered after 100,000 tombstones of
				any type have timed out in the local <keyword keyref="product_name"/> member. You
				can optionally set the <codeph>gemfire.tombstone-gc-threshold</codeph> property to a
				value smaller than 100000 to perform garbage collection more frequently. </p>
			<note>
				<p>To avoid out-of-memory errors, a <keyword keyref="product_name"/> member also
				initiates garbage collection for tombstones when the amount of free memory drops
				below 30 percent of total memory.
				</p>
			</note>
			<p>You can monitor the total number of tombstones in a cache using the
					<codeph>tombstoneCount</codeph> statistic in <codeph>CachePerfStats</codeph>.
				The <codeph>tombstoneGCCount</codeph> statistic records the total number of
				tombstone garbage collection cycles that a member has performed.
					<codeph>replicatedTombstonesSize</codeph> and
					<codeph>nonReplicatedTombstonesSize</codeph> show the approximate number of
				bytes that are currently consumed by tombstones in replicated or partitioned
				regions, and in non-replicated regions, respectively. See <xref
					href="../../reference/statistics/statistics_list.xml#statistics_list"
					format="dita" scope="local"/>. </p>
			<section id="section_4D0140E96A3141EB8D983D0A43464097">
				<title>About Region.clear() Operations</title>
				<p>Region entry version stamps and tombstones ensure consistency only when
					individual entries are destroyed. A <codeph>Region.clear()</codeph> operation,
					however, operates on all entries in a region at once. To provide consistency for
						<codeph>Region.clear()</codeph> operations, <keyword keyref="product_name"/>
					obtains a distributed read/write lock for the region, which blocks all
					concurrent updates to the region. Any updates that were initiated before the
					clear operation are allowed to complete before the region is cleared. </p>
			</section>
		</body>
	</topic>
	<topic id="topic_32ACFA5542C74F3583ECD30467F352B0">
		<title>Transactions with Consistent Regions</title>
		<shortdesc>A transaction that modifies a region having consistency checking enabled
			generates all necessary version information for region updates when the transaction
			commits. </shortdesc>
		<body>
			<p>If a transaction modifies a normal, preloaded or empty region, the transaction is
				first delegated to a <keyword keyref="product_name"/> member that holds a replicate
				for the region. This behavior is similar to the transactional behavior for
				partitioned regions, where the partitioned region transaction is forwarded to a
				member that hosts the primary for the partitioned region update. </p>
			<p>The limitation for transactions on normal, preloaded or or empty regions is that,
				when consistency checking is enabled, a transaction cannot perform a
					<codeph>localDestroy</codeph> or <codeph>localInvalidate</codeph> operation
				against the region. <keyword keyref="product_name"/> throws an
					<codeph>UnsupportedOperationInTransactionException</codeph> exception in such
				cases. An application should use a <codeph>Destroy</codeph> or
					<codeph>Invalidate</codeph> operation in place of a
					<codeph>localDestroy</codeph> or <codeph>localInvalidate</codeph> when
				consistency checks are enabled. </p>
		</body>
	</topic>
</dita>
