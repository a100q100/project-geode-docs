<?xml version="1.0"?>
<!DOCTYPE concept PUBLIC "-//OASIS//DTD DITA Concept//EN" "concept.dtd">
<concept id="concept_357ABE91AAA042D2A20328BD01FEB882">
	<title>Network Partitioning Scenarios</title>
	<shortdesc>This topic describes network partitioning scenarios and what happens to the
		partitioned sides of the distributed system. </shortdesc>
	<conbody>
		<p>
			<image id="image_6ED88C6911EE4C68A19353ABD7B1552A"
				href="../../images_svg/network_partition_scenario.svg"/>
		</p>
		<section id="section_DAFBCB8BB421453EB6C5B4A348640762">
			<title>What the Losing Side Does</title>
			<p> In a network partitioning scenario, the "losing side" constitutes the cluster
				partition where the membership coordinator has detected that there is an
				insufficient quorum of members to continue. </p>
			<p>The membership coordinator calculates membership weight change after sending out its
				view preparation message. If a quorum of members does not remain after the view
				preparation phase, the coordinator on the "losing side" declares a network partition
				event and sends a network-partition-detected UDP message to the members. The
				coordinator then closes its distributed system with a
					<codeph>ForcedDisconnectException</codeph>. If a member fails to receive the
				message before the coordinator closes the connection, it is responsible for
				detecting the event on its own. </p>
			<p>When the losing side discovers that a network partition event has occurred, all peer
				members receive a <codeph>RegionDestroyedException</codeph> with
					<codeph>Operation</codeph>: <codeph>FORCED_DISCONNECT</codeph>. </p>
			<p>If a <codeph>CacheListener</codeph> is installed, the <codeph>afterRegionDestroy</codeph>
				callback is invoked with a <codeph>RegionDestroyedEvent</codeph>, as shown in this
				example logged by the losing side's callback. The peer member process IDs are 14291
				(lead member) and 14296, and the locator is 14289.
				<codeblock>[info 2008/05/01 11:14:51.853 PDT &lt;CloserThread&gt; tid=0x4a] 
Invoked splitBrain.SBListener: afterRegionDestroy in client1 whereIWasRegistered: 14291 
event.isReinitializing(): false 
event.getDistributedMember(): thor(14291):40440/34132 
event.getCallbackArgument(): null 
event.getRegion(): /TestRegion 
event.isOriginRemote(): false 
Operation: FORCED_DISCONNECT 
Operation.isDistributed(): false 
Operation.isExpiration(): false </codeblock>
			</p>
			<p>Peers still actively performing operations on the cache may see
					<codeph>ShutdownException</codeph>s or <codeph>CacheClosedException</codeph>s
				with <codeph>Caused by: ForcedDisconnectException</codeph>. </p>
		</section>
		<section id="section_E6E914107FE64C0F9D8F7DA142D00AD7">
			<title>What Isolated Members Do</title>
			<p>When a member is isolated from all locators, it is unable to receive membership view
				changes. It can't know if the current coordinator is present or, if it has left,
				whether there are other members available to take over that role. In this condition,
				a member will eventually detect the loss of all other members and will use the loss
				threshold to determine whether it should shut itself down. In the case of a
				distributed system with 2 locators and 2 cache servers, the loss of communication
				with the non-lead cache server plus both locators would result in this situation and
				the remaining cache server would eventually shut itself down. </p>
		</section>
	</conbody>
</concept>
