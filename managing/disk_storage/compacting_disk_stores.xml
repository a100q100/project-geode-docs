<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE concept PUBLIC "-//OASIS//DTD DITA Concept//EN" "http://docs.oasis-open.org/dita/v1.1/OS/dtd/concept.dtd">
<concept id="compacting_disk_stores">
	<title>Running Compaction on Disk Store Log Files</title>
	<conbody>
		<section id="section_64BA304595364E38A28098EB09494531">
			<p>When a cache operation is added to a disk store, any preexisting operation record for
				the same entry becomes obsolete, and <keyword keyref="product_name_long"/> marks it
				as garbage. For example, when you create an entry, the create operation is added to
				the store. If you update the entry later, the update operation is added and the
				create operation becomes garbage. <keyword keyref="product_name"/> does not remove
				garbage records as it goes, but it tracks the percentage of garbage in each
				operation log, and provides mechanisms for removing garbage to compact your log
				files. </p>
			<p><keyword keyref="product_name"/> compacts an old operation log by copying all
				non-garbage records into the current log and discarding the old files. As with
				logging, oplogs are rolled as needed during compaction to stay within the max oplog
				setting. </p>
			<p>You can configure the system to automatically compact any closed operation log when
				its garbage content reaches a certain percentage. You can also manually request
				compaction for online and offline disk stores. For the online disk store, the
				current operation log is not available for compaction, no matter how much garbage it
				contains. </p>
		</section>
		<section id="section_98C6B6F48E4F4F0CB7749E426AF4D647">
			<title>Log File Compaction for the Online Disk Store </title>
			<p>
				<image href="../../images/diskStores-3.gif"
					id="image_7E34CC58B13548B196DAA15F5B0A0ECA" placement="break"/>
			</p>
			<p>Offline compaction runs essentially in the same way, but without the incoming cache
				operations. Also, because there is no current open log, the compaction creates a new
				one to get started. </p>
		</section>
		<section id="section_96E774B5502648458E7742B37CA235FF">
			<title>Run Online Compaction</title>
			<p>Old log files become eligible for online compaction when their garbage content
				surpasses a configured percentage of the total file. A record is garbage when its
				operation is superseded by a more recent operation for the same object. During
				compaction, the non-garbage records are added to the current log along with new
				cache operations. Online compaction does not block current system operations.</p>
				<ul
					id="ul_DC1F95BD89C841F39EDEA8F96E4BB77B">
					<li id="li_A58CD62D447D48A5832E780527CF7540"><b>Automatic compaction</b>. When
							<codeph>auto-compact</codeph> is true, <keyword keyref="product_name"/>
						automatically compacts each oplog when its garbage content surpasses the
							<codeph>compaction-threshold</codeph>. This takes cycles from your other
						operations, so you may want to disable this and only do manual compaction,
						to control the timing. </li>
					<li id="li_63CF8C35153D4173AADF7DC35FEC61F9"><b>Manual compaction</b>. To run
						manual compaction: <ul id="ul_515C26B5253B4DBE8F873970D6AF3727">
							<li id="li_6C6EA6D9361444CD9C372B0449EE95D9">Set the disk store
								attribute <codeph>allow-force-compaction</codeph> to true. This
								causes <keyword keyref="product_name"/> to maintain extra data about
								the files so it can compact on demand. This is disabled by default
								to save space. You can run manual online compaction at any time
								while the system is running. Oplogs eligible for compaction based on
								the <codeph>compaction-threshold</codeph> are compacted into the
								current oplog. </li>
							<li id="li_35F9797DECEF49F692FEB0E9DC30784D">Run manual compaction as
								needed. <keyword keyref="product_name"/> has two types of manual
								compaction: <ul id="ul_D816B881E80541BCBE34822F362E49C0">
									<li id="li_1BB8F53361804627AC131C954DA71F79">Compact the logs
										for a single online disk store through the API, with the
											<codeph>forceCompaction</codeph> method. This method
										first rolls the oplogs and then compacts them. Example:
										<codeblock>myCache.getDiskStore("myDiskStore").forceCompaction();</codeblock>
									</li>
									<li id="li_C0EC05EFF45F49E9A352C0019C836F06">Using
											<codeph>gfsh</codeph>, compact a disk store in a
										distributed system with the <xref
											href="../../tools_modules/gfsh/command-pages/compact.xml#topic_F113C95C076F424E9AA8AC4F1F6324CC"
											type="topic" format="dita" scope="local"/> command.
										Examples: <codeblock>gfsh&gt;compact disk-store --name=Disk1

gfsh&gt;compact disk-store --name=Disk1 --group=MemberGroup1,MemberGroup2</codeblock>
										<note> You need to be connected to a JMX Manager in
												<codeph>gfsh</codeph> to run this command. </note>
									</li>
								</ul>
							</li>
						</ul>
					</li>
				</ul>
		</section>
		<section id="section_25BDB098E9584EAA9BC6582597544726">
			<title>Run Offline Compaction</title>
			<p>Offline compaction is a manual process. All log files are compacted as much as
				possible, regardless of how much garbage they hold. Offline compaction creates new
				log files for the compacted log records. </p>
			<p>Using <codeph>gfsh</codeph>, compact individual offline disk stores with the <xref
					href="../../tools_modules/gfsh/command-pages/compact.xml#topic_9CCFCB2FA2154E16BD775439C8ABC8FB"
					type="topic" format="dita" scope="local"
					><?xm-replace_text compact offline-disk-store?></xref> command: </p>
				<codeblock>gfsh&gt;compact offline-disk-store --name=Disk2 --disk-dirs=/Disks/Disk2

gfsh&gt;compact offline-disk-store --name=Disk2 --disk-dirs=/Disks/Disk2 
--max-oplog-size=512 -J=-Xmx1024m</codeblock>
			<p>
				<note>Do not perform offline compaction on the baseline directory of an incremental
					backup. </note>
			</p>
			<p>You must provide all of the directories in the disk store. If no oplog max size is
				specified, <keyword keyref="product_name"/> uses the system default. </p>
			<p>Offline compaction can take a lot of memory. If you get a
					<codeph>java.lang.OutOfMemory</codeph> error while running this, you may need to
				increase your heap size with the <codeph>-J=-Xmx</codeph> parameter. </p>
		</section>
		<section id="section_D2374039480947C5AE4CC64167E60978">
			<title>Performance Benefits of Manual Compaction</title>
			<p>You can improve performance during busy times if you disable automatic compaction and
				run your own manual compaction during lighter system load or during downtimes. You
				could run the API call after your application performs a large set of data
				operations. You could run <codeph>compact disk-store</codeph> command every night
				when system use is very low. </p>
			<p>To follow a strategy like this, you need to set aside enough disk space to
				accommodate all non-compacted disk data. You might need to increase system
				monitoring to make sure you do not overrun your disk space. You may be able to run
				only offline compaction. If so, you can set <codeph>allow-force-compaction</codeph>
				to false and avoid storing the information required for manual online compaction.
			</p>
		</section>
		<section id="section_A9EE86F662EE4D46A327C336E901A0F2">
			<title>Directory Size Limits</title>
			<p>Reaching directory size limits during has different results depending on whether you
				are running an automatic or manual compaction: </p>
				<ul
					id="ul_2458B7E568AE4778B5660BF7E5637CB0">
					<li id="li_207983DED512409E84DE9A9388A665E7">For automatic compaction, the
						system logs a warning, but does not stop. </li>
					<li id="li_1822C494A1204821BD9DCC3EF29DAE02">For manual compaction, the
						operation stops and returns a <codeph>DiskAccessException</codeph> to the
						calling process, reporting that the system has run out of disk space. </li>
				</ul>
		</section>
		<section id="section_7A311038408440D49097B8FA4E2BCED9">
			<title>Example Compaction Run</title>
			<p>In this example offline compaction run listing, the disk store compaction had nothing
				to do in the <codeph>*_3.*</codeph> files, so they were left alone. The
					<codeph>*_4.*</codeph> files had garbage records, so the oplog from them was
				compacted into the new <codeph>*_5.*</codeph> files.</p>
				<codeblock>bash-2.05$ ls -ltra backupDirectory
total 28
-rw-rw-r--   1 user users          3 Apr  7 14:56 BACKUPds1_3.drf
-rw-rw-r--   1 user users         25 Apr  7 14:56 BACKUPds1_3.crf
drwxrwxr-x   3 user users       1024 Apr  7 15:02 ..
-rw-rw-r--   1 user users       7085 Apr  7 15:06 BACKUPds1.if
-rw-rw-r--   1 user users         18 Apr  7 15:07 BACKUPds1_4.drf
-rw-rw-r--   1 user users       1070 Apr  7 15:07 BACKUPds1_4.crf
drwxrwxr-x   2 user users        512 Apr  7 15:07 .

bash-2.05$ gfsh

gfsh&gt;validate offline-disk-store --name=ds1 --disk-dirs=backupDirectory

/root: entryCount=6
/partitioned_region entryCount=1 bucketCount=10
Disk store contains 12 compactable records.
Total number of region entries in this disk store is: 7

gfsh&gt;compact offline-disk-store --name=ds1 --disk-dirs=backupDirectory
Offline compaction removed 12 records.
Total number of region entries in this disk store is: 7

gfsh&gt;exit

bash-2.05$ ls -ltra backupDirectory
total 16
-rw-rw-r--   1 user users          3 Apr  7 14:56 BACKUPds1_3.drf
-rw-rw-r--   1 user users         25 Apr  7 14:56 BACKUPds1_3.crf
drwxrwxr-x   3 user users       1024 Apr  7 15:02 ..
-rw-rw-r--   1 user users          0 Apr  7 15:08 BACKUPds1_5.drf
-rw-rw-r--   1 user users        638 Apr  7 15:08 BACKUPds1_5.crf
-rw-rw-r--   1 user users       2788 Apr  7 15:08 BACKUPds1.if
drwxrwxr-x   2 user users        512 Apr  7 15:09 .
bash-2.05$</codeblock>
		</section>
	</conbody>
</concept>
