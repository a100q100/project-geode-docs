<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE concept PUBLIC "-//OASIS//DTD DITA Concept//EN" "http://docs.oasis-open.org/dita/v1.1/OS/dtd/concept.dtd">
<concept id="slow_recv">
	<title>Managing Slow Receivers</title>
	<shortdesc>If the receiver fails to receive a message, the sender continues to attempt to
		deliver the message as long as the receiving member is still in the distributed system. </shortdesc>
	<conbody>
		<p> During the retry cycle, <keyword keyref="product_name"/> throws warnings that include
			this string: </p>
		<codeblock>will reattempt</codeblock>
		<p>The warnings are followed by an informational message when the delivery finally succeeds. </p>
		<p>For distributed regions, the scope of a region determines whether distribution
			acknowledgments and distributed synchronization are required. Partitioned regions ignore
			the scope attribute, but for the purposes of this discussion you should think of them as
			having an implicit distributed-ack scope. </p>
		<p>By default, distribution between system members is performed synchronously. With
			synchronous communication, when one member is slow to receive, it can cause its
			producers to slow down as well. This, of course, can lead to general performance
			problems in the distributed system. </p>
		<p>If you are experiencing slow performance and are sending large objects (multiple
			megabytes), before implementing these slow receiver options make sure your socket buffer
			sizes are appropriate for the size of the objects you distribute. The socket buffer size
			is set using socket-buffer-size in the <codeph>gemfire.properties</codeph> file. </p>
		<p><b>Managing Slow distributed-no-ack Receivers</b>
		</p>
		<p>You can configure your consumer members so their messages are queued separately when they
			are slow to respond. The queueing happens in the producer members when the producers
			detect slow receipt and allows the producers to keep sending to other consumers at a
			normal rate. Any member that receives data distribution can be configured as described
			in this section. </p>
		<p>The specifications for handling slow receipt primarily affect how your members manage
			distribution for regions with distributed-no-ack scope, where distribution is
			asynchronous, but the specifications can affect other distributed scopes as well. If no
			regions have distributed-no-ack scope, the mechanism is unlikely to kick in at all. When
			slow receipt handling does kick in, however, it affects all distribution between the
			producer and that consumer, regardless of scope. </p>
			<note>
				<p>These slow receiver options are disabled in systems using SSL. See <xref
					href="../security/ssl_overview.xml" type="concept" format="dita"
					scope="local"><?xm-replace_text SSL?></xref>. 
				</p>
			</note>
		<p>Each consumer member determines how its own slow behavior is to be handled by its
			producers. The settings are specified as distributed system connection properties. This
			section describes the settings and lists the associated properties. </p>
			<ul
				id="ul_34B7B6CE0C9F4AF18F711788181B26BB">
				<li id="li_FD952B8AA10541849D3EE197CB022020">async-distribution-timeout—The
					distribution timeout specifies how long producers are to wait for the consumer
					to respond to synchronous messaging before switching to asynchronous messaging
					with that consumer. When a producer switches to asynchronous messaging, it
					creates a queue for that consumer’s messages and a separate thread to handle the
					communication. When the queue empties, the producer automatically switches back
					to synchronous communication with the consumer. These settings affect how long
					your producer’s cache operations might block. The sum of the timeouts for all
					consumers is the longest time your producer might block on a cache operation. </li>
				<li id="li_AF64EDF6A48646C396D00E141FD2EFAD">async-queue-timeout—The queue timeout
					sets a limit on the length of time the asynchronous messaging queue can exist
					without a successful distribution to the slow receiver. When the timeout is
					reached, the producer asks the consumer to leave the distributed system. </li>
				<li id="li_76790E3676B240C6AE6F13CBFCF0A0DF">async-max-queue-size—The maximum queue
					size limits the amount of memory the asynchronous messaging queue can consume.
					When the maximum is reached, the producer asks the consumer to leave the
					distributed system. </li>
			</ul>
		<p><b>Configuring Async Queue Conflation</b>
		</p>
		<p>When the scope is distributed-no-ack scope, you can configure the producer to conflate
			entry update messages in its queues, which may further speed communication. By default,
			distributed-no-ack entry update messages are not conflated. The configuration is set in
			the producer at the region level. </p>
		<p><b>Forcing the Slow Receiver to Disconnect</b>
		</p>
		<p>If either of the queue timeout or maximum queue size limits is reached, the producer
			sends the consumer a high-priority message (on a different TCP connection than the
			connection used for cache messaging) telling it to disconnect from the distributed
			system. This prevents growing memory consumption by the other processes that are queuing
			changes for the slow receiver while they wait for that receiver to catch up. It also
			allows the slow member to start fresh, possibly clearing up the issues that were causing
			it to run slowly. </p>
		<p>When a producer gives up on a slow receiver, it logs one of these types of warnings:</p>
			<ul
				id="ul_19433186B9FD4D56BFA4BC48856B54BD">
				<li id="li_3375351BD7A24835BCF80BF144557FAC">Blocked for time ms which is longer
					than the max of asyncQueueTimeout ms so asking slow receiver slow_receiver_ID to
					disconnect. </li>
				<li id="li_6B72BC691D1940699A4E34ABF80A4B36">Queued bytes exceed max of
					asyncMaxQueueSize so asking slow receiver slow_receiver_ID to disconnect. </li>
			</ul>
		<p>When a process disconnects after receiving a request to do so by a producer, it logs a
			warning message of this type: </p>
			<ul id="ul_28BE03E6C66A4E238C8B7B3E29FDB874">
				<li id="li_773DE682A4B04A81859EE62C6271C4E3">Disconnect forced by producer because
					we were too slow. </li>
			</ul>
		<p>These messages only appear in your logs if logging is enabled and the log level is set to
			a level that includes warning (which it does by default). See <xref scope="local"
				href="../logging/logging.xml"
				type="concept" format="dita"><?xm-replace_text Logging?></xref>. </p>
		<p>If your consumer is unable to receive even high priority messages, only the producer’s
			warnings will appear in the logs. If you see only producer warnings, you can restart the
			consumer process. Otherwise, the <keyword keyref="product_name"/> failure detection code
			will eventually cause the member to leave the distributed system on its own. </p>
		<p><b>Use Cases</b>
		</p>
		<p>These are the main use cases for the slow receiver specifications: </p>
			<ul
				id="ul_142C38D316814498BAC3335885042D6C">
				<li id="li_AC266A7388FF49138F0CE515F7CE9012">Message bursts—With message bursts, the
					socket buffer can overflow and cause the producer to block. To keep from
					blocking, first make sure your socket buffer is large enough to handle a normal
					number of messages (using the socket-buffer-size property), then set the async
					distribution timeout to 1. With this very low distribution timeout, when your
					socket buffer does fill up, the producer quickly switches to async queueing. Use
					the distribution statistics, asyncQueueTimeoutExceeded and
					asyncQueueSizeExceeded, to make sure your queue settings are high enough to
					avoid forcing unwanted disconnects during message bursts. </li>
				<li id="li_ABD9CB7E06414228B7AE894884DB0CB7">Unhealthy or dead members—When members
					are dead or very unhealthy, they may not be able to communicate with other
					distributed system members. The slow receiver specifications allow you to force
					crippled members to disconnect, freeing up resources and possibly allowing the
					members to restart fresh. To configure for this, set the distribution timeout
					high (one minute), and set the queue timeout low. This is the best way to avoid
					queueing for momentary slowness, while still quickly telling very unhealthy
					members to leave the distributed system. </li>
				<li id="li_AC909E9964EA41E2BB2CA0C9ADECE860">Combination message bursts and
					unhealthy members—To configure for both of the above situations, set the
					distribution timeout low and the queue timeout high, as for the message bursts
					scenario. </li>
			</ul>
		<p><b>Managing Slow distributed-ack Receivers</b>
		</p>
		<p>When using a distribution scope other than distributed-no-ack, alerts are issued for slow
			receivers. A member that isn’t responding to messages may be sick, slow, or missing.
			Sick or slow members are detected in message transmission and reply-wait processing
			code, triggering a warning alert first. If a member still isn’t responding, a severe
			warning alert is issued, indicating that the member may be disconnected from the
			distributed system. This alert sequence is enabled by setting the ack-wait-threshold and
			the ack-severe-alert-threshold to some number of seconds. </p>
		<p>When ack-severe-alert-threshold is set, regions are configured to use ether
			distributed-ack or global scope, or use the partition data policy. <keyword
				keyref="product_name"/> will wait for a total of ack-wait-threshold seconds for a
			response to a cache operation, then it logs a warning alert ("Membership: requesting
			removal of entry(#). Disconnected as a slow-receiver"). After waiting an additional
			ack-severe-alert-threshold seconds after the first threshold is reached, the system also
			informs the failure detection mechanism that the receiver is suspect and may be
			disconnected, as shown in the following figure. </p>
		<image placement="break" id="image_BA474143B16744F28DE0AB1CAD00FB48"
			href="../../images_svg/member_severe_alert.svg"/>
		<p>The events occur in this order: </p>
			<ol id="ol_29295799A8AD49238FCAC7E8B3A24C53">
				<li id="li_D7124E0DC9814FCF960234EFC2E1C27B">CACHE_OPERATION - transmission of cache
					operation is initiated. </li>
				<li id="li_E35B3014A8924C088B1155C948A29C9B">SUSPECT - identified as a suspect by
					ack-wait-threshold, which is the maximum time to wait for an acknowledge before
					initiating failure detection. </li>
				<li id="li_3D1169FCEDD04FA1B11F1327534AA041">I AM ALIVE - notification to the system
					in response to failure detection queries, if the process is still alive. A new
					membership view is sent to all members if the suspect process fails to answer
					with I AM ALIVE. </li>
				<li id="li_8F504017CE1D4762817F6C30E3561BE0">SEVERE ALERT- the result of
					ack-severe-wait-threshold elapsing without receiving a reply. </li>
			</ol>
		<p>When a member fails suspect processing, its cache is closed and its CacheListeners are
			notified with the afterRegionDestroyed notification. The RegionEvent passed with this
			notification has a CACHE_CLOSED operation and a FORCED_DISCONNECT operation, as shown in
			the FORCED_DISCONNECT example. </p>
			<codeblock>public static final Operation FORCED_DISCONNECT 
= new Operation("FORCED_DISCONNECT",
		true, // isLocal
		true, // isRegion
		OP_TYPE_DESTROY,
		OP_DETAILS_NONE
		);
			</codeblock>
		<p>A cache closes due to being expelled from the distributed system by other members.
			Typically, this happens when a member becomes unresponsive and does not respond to
			heartbeat requests within the member-timeout period, or when ack-severe-alert-threshold
			has expired without a response from the member. </p>
			<note>
				<p>This is marked as a region operation.
				</p>
			</note>
		<p>Other members see the normal membership notifications for the departing member. For
			instance, RegionMembershipListeners receive the afterRemoteRegionCrashed notification,
			and SystemMembershipListeners receive the memberCrashed notification. </p>
	</conbody>
</concept>
