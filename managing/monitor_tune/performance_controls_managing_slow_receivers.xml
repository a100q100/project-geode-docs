<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE concept PUBLIC "-//OASIS//DTD DITA Concept//EN" "http://docs.oasis-open.org/dita/v1.1/OS/dtd/concept.dtd">
<concept id="perf">
	<title>Management of Slow Receivers</title>
	<shortdesc id="shortdesc_fh1_lpb_rr">You have several options for handling slow members that
		receive data distribution. The slow receiver options control only to peer-to-peer
		communication between distributed regions using TCP/IP. This topic does not apply to
		client/server or multi-site communication, or to communication using the UDP unicast or IP
		multicast protocols. </shortdesc>
	<conbody id="conbody_l4j_lpb_rr">
		<p>Most of the options for handling slow members are related to on-site configuration during
			system integration and tuning. For this information, see <xref
				href="slow_receivers.xml" type="concept" format="dita" scope="local"
				><?xm-replace_text Slow Receivers with TCP/IP?></xref>. </p>
		<p>Slowing is more likely to occur when applications run many threads, send large messages
			(due to large entry values), or have a mix of region configurations. </p>
		<p>
			<note>If you are experiencing slow performance and are sending large objects (multiple
				megabytes), before implementing these slow receiver options make sure your socket
				buffer sizes are large enough for the objects you distribute. The socket buffer size
				is set using gemfire.socket-buffer-size. </note>
		</p>
		<p>By default, distribution between system members is performed synchronously. With
			synchronous communication, when one member is slow to receive, it can cause its producer
			members to slow down as well. This can lead to general performance problems in the
			distributed system. </p>
		<p>The specifications for handling slow receipt primarily affect how your members manage
			distribution for regions with distributed-no-ack scope, but it can affect other
			distributed scopes as well. If no regions have distributed-no-ack scope, this mechanism
			is unlikely to kick in at all. When slow receipt handling does kick in, however, it
			affects all distribution between the producer and consumer, regardless of scope.
			Partitioned regions ignore the scope attribute, but for the purposes of this discussion
			you should think of them as having an implicit distributed-ack scope. </p>
		<p><b>Configuration Options</b>
		</p>
		<p>The slow receiver options are set in the producer member’s region attribute,
			enable-async-conflation, and in the consumer member’s async*
				<codeph>gemfire.properties</codeph> settings. </p>
		<p><b>Delivery Retries</b>
		</p>
		<p>If the receiver fails to receive a message, the sender continues to attempt to deliver
			the message as long as the receiving member is still in the distributed system. During
			the retry cycle, throws warnings that include this string: </p>
			<codeblock>will reattempt</codeblock>
		<p>The warnings are followed by an info message when the delivery finally succeeds. </p>
		<p><b>Asynchronous Queueing For Slow Receivers</b>
		</p>
		<p>Your consumer members can be configured so that their producers switch to asynchronous
			messaging if the consumers are slow to respond to cache message distribution. </p>
		<p>When a producer switches, it creates a queue to hold and manage that consumer’s cache
			messages. When the queue empties, the producer switches back to synchronous messaging
			for the consumer. The settings that cause the producers to switch are specified on the
			consumer side in <codeph>gemfire.properties</codeph> file settings. </p>
		<p>If you configure your consumers for slow receipt queuing, and your region scope is
			distributed-no-ack, you can also configure the producer to conflate entry update
			messages in its queues. This configuration option is set as the region attribute
			enable-async-conflation. By default distributed-no-ack entry update messages are not
			conflated. </p>
		<p>Depending on the application, conflation can greatly reduce the number of messages the
			producer needs to send to the consumer. With conflation, when an entry update is added
			to the queue, if the last operation queued for that key is also an update operation, the
			previously enqueued update is removed, leaving only the latest update to be sent to the
			consumer. Only entry update messages originating in a region with distributed-no-ack
			scope are conflated. Region operations and entry operations other than updates are not
			conflated. </p>
		<p>
			<image placement="break" id="image_0FD90F27762F4440B9ECC40803988038"
				href="../../images_svg/async_system_queue_conflation.svg"/>
		</p>
		<p>Some conflation may not occur because entry updates are sent to the consumer before they
			can be conflated. For this example, assume no messages are sent while the update for Key
			A is added. </p>
		<p>
			<note>This method of conflation behaves the same as server-to-client conflation. </note>
		</p>
		<p>You can enable queue conflation on a region-by-region basis. You should always enable it
			unless it is incompatible with your application needs. Conflation reduces the amount of
			data queued and distributed. </p>
		<p>These are reasons why conflation might not work for your application:</p>
			<ul
				id="ul_649B3D10A5704719AA009CA7154B6A39">
				<li id="li_EF005A6CB594451B813D96EF44AEA2FB">With conflation, earlier entry updates
					are removed from the queue and replaced by updates sent later in the queue. This
					is problematic for applications that depend on a specific ordering of entry
					modifications. For example, if your receiver has a CacheListener that needs to
					know about every state change, you should disable conflation. </li>
				<li id="li_97E534141A394435AA0C8BC6334E8B76">If your queue remains in use for a
					significant period and you have entries that are updated frequently, you could
					have a series of update message replacements resulting in a notable delay in the
					arrival of any update for some entries. Imagine that update 1, before it is
					sent, is removed in favor of a later update 2. Then, before update 2 can be
					sent, it is removed in favor of update 3, and so on. This could result in
					unacceptably stale data on the receiver. </li>
			</ul>
	</conbody>
</concept>
